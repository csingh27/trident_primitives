{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T16:32:22.659248Z",
     "start_time": "2022-03-13T16:32:22.647928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 15:34:54.480447: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 15:34:54.598742: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-14 15:34:55.147105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
      "2023-05-14 15:34:55.147161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
      "2023-05-14 15:34:55.147166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import scipy\n",
    "import sklearn\n",
    "from umap import UMAP\n",
    "\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from netcal.metrics import ECE, MCE\n",
    "from netcal.scaling import TemperatureScaling\n",
    "from netcal.presentation import ReliabilityDiagram\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T16:32:26.822691Z",
     "start_time": "2022-03-13T16:32:26.811457Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_report(l, confidence=0.95):\n",
    "    for df in l:\n",
    "        df.columns = list(df.columns[1:]) + ['model_name']\n",
    "        df['accuracy'] = 100 * df['accuracy']\n",
    "        a = df['accuracy'].to_numpy()\n",
    "        n = len(a)\n",
    "        m, se = np.mean(a), scipy.stats.sem(a)\n",
    "        h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "        print(m, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T16:32:27.044423Z",
     "start_time": "2022-03-13T16:32:27.036342Z"
    }
   },
   "outputs": [],
   "source": [
    "def conf_int(data, confidence=0.95):\n",
    "    a = data.to_numpy()\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T16:32:27.241348Z",
     "start_time": "2022-03-13T16:32:27.235174Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_metrics(df):\n",
    "    df.columns = ['task', '0', '1', '2', '3', '4', 'actual']\n",
    "    df[['0', '1', '2', '3', '4']] = F.softmax(torch.tensor(\n",
    "        df[['0', '1', '2', '3', '4']].to_numpy()), dim=1).numpy()\n",
    "    \n",
    "    # Calculate ECE, MCE\n",
    "    n_bins = 10\n",
    "    confidences = df[['0', '1', '2', '3', '4']].to_numpy()\n",
    "    ground_truth = df['actual'].to_numpy()\n",
    "    ece = ECE(n_bins)\n",
    "    mce = MCE(n_bins)\n",
    "    uncalibrated_score_ece = ece.measure(confidences, ground_truth)\n",
    "    temperature = TemperatureScaling()\n",
    "    temperature.fit(confidences, ground_truth)\n",
    "    calibrated = temperature.transform(confidences)\n",
    "    calibrated_score_ece = ece.measure(calibrated, ground_truth)\n",
    "    \n",
    "    uncalibrated_score_mce = mce.measure(confidences, ground_truth)\n",
    "    calibrated_score_mce = mce.measure(calibrated, ground_truth)\n",
    "\n",
    "    # Reliability diagram\n",
    "    diagram = ReliabilityDiagram(n_bins)\n",
    "    diagram.plot(calibrated, ground_truth)\n",
    "    \n",
    "    return calibrated_score_ece, calibrated_score_mce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T16:32:27.566934Z",
     "start_time": "2022-03-13T16:32:27.558046Z"
    }
   },
   "outputs": [],
   "source": [
    "def report(df, tasks, confidence=0.95):\n",
    "    df.columns = list(df.columns[1:]) + ['model_name']\n",
    "    df['accuracy'] = 100 * df['accuracy']\n",
    "    a = df['accuracy'].to_numpy()\n",
    "    a = np.split(a, len(a)/tasks, axis=0)\n",
    "    for accs in a:\n",
    "        n = len(accs)\n",
    "        m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "        h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "        print(m, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T19:40:42.314167Z",
     "start_time": "2022-03-13T19:40:42.304914Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_summarize(dfs, columns, meta_batch_size, batch_size):\n",
    "    dfs[0] = dfs[0].groupby(np.arange(len(dfs[0])) // meta_batch_size).mean()\n",
    "    \n",
    "    dfs[1].columns = list(dfs[1].columns[1:]) + ['model_name']\n",
    "    valid = dfs[1].groupby('model_name', as_index=False)[dfs[1].columns].mean()\n",
    "    valid['iter'] = valid['model_name'].apply(\n",
    "        lambda x: int(x[x.index('_') + 1:-3]))\n",
    "    valid.sort_values(by=['iter'], inplace=True)\n",
    "    valid.drop(columns=['model_name'], inplace=True)\n",
    "    print(valid)\n",
    "    valid['accuracy'] = 100 * valid['accuracy'] \n",
    "\n",
    "    # Summarizing best valid scores\n",
    "    ind = valid[valid['accuracy'] == valid['accuracy'].max()]['iter'].values[0]\n",
    "    t = dfs[1][dfs[1]['model_name'] == 'model_' + str(ind) + '.pt']\n",
    "    t['accuracy'] = 100 * t['accuracy']\n",
    "    print('Validation Metrics Stats of Best Model at {}-th Iteration'.format(ind))\n",
    "    display(t.describe())\n",
    "\n",
    "    dfs[0].drop(columns=['task'], inplace=True)\n",
    "    dfs[0].reset_index(drop=True, inplace=True)\n",
    "    valid.reset_index(drop=True, inplace=True)\n",
    "    dfs[0].columns = [str(c)+'_train' for c in columns]\n",
    "    dfs[0]['accuracy_train'] = 100 * dfs[0]['accuracy_train']\n",
    "    dfs[0]['iter'] = dfs[0].index\n",
    "    \n",
    "    # Plotting\n",
    "    ctv = [str(c)+'_train' for c in columns]\n",
    "    fig = px.line(dfs[0], x=dfs[0].index, y=ctv)\n",
    "    fig.add_scatter(x=valid['iter'], y=valid['accuracy'], name='accuracy_valid')\n",
    "    fig.show()\n",
    "\n",
    "    #return df, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing runs from CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T19:40:45.044369Z",
     "start_time": "2022-03-13T19:40:43.738273Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [task, accuracy, ELBO, Label_KL, Style_KL, Reconst_Loss, CE_Loss]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "path_train = \"/home/dfki.uni-bremen.de/csingh/DFKI/PhysWM/trident_primitives/output/meta_lrng/files/folder/learning_to_meta-learn/logs/TRIDENT_primitives_5-way_4-shot_1-queries/exp1\"\n",
    "path_test = \"/home/dfki.uni-bremen.de/csingh/DFKI/PhysWM/trident_primitives/output/meta_lrng/files/folder/learning_to_meta-learn/logs/TRIDENT_test_primitives_5-way_4-shot_1-queries/exp1\"\n",
    "path = path_train\n",
    "\n",
    "train_path = path + \"/train.csv\"\n",
    "test_path = path + \"/test.csv\"\n",
    "valid_path = path + \"/valid.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_valid = pd.read_csv(valid_path)\n",
    "df_valid = df_test\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "df_test = df_test[~(df_test['CE_Loss'] == 'model_last.pt')]\n",
    "df_valid = df_valid[~(df_valid['CE_Loss'] == 'model_last.pt')]\n",
    "print(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T19:40:51.197351Z",
     "start_time": "2022-03-13T19:40:47.212501Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [iter]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_summarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_valid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mELBO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabel_KL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSemantic_KL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReconst_Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCE_Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mplot_summarize\u001b[0;34m(dfs, columns, meta_batch_size, batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m valid\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(valid)\n\u001b[0;32m---> 11\u001b[0m valid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mvalid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Summarizing best valid scores\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ind \u001b[38;5;241m=\u001b[39m valid[valid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m valid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "plot_summarize([df_train, df_valid], ['accuracy', 'ELBO', 'Label_KL', 'Semantic_KL', 'Reconst_Loss', 'CE_Loss'], 20, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T19:41:30.946345Z",
     "start_time": "2022-03-13T19:41:30.792583Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'PATH to test.csv')\n",
    "test_report([df_test]) # Can also run test.py multiple times for multiple test.csv's and add in the argument list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prob Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T01:01:29.108509Z",
     "start_time": "2022-02-15T01:01:28.789721Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds = pd.read_csv('PATH TO preds.csv')\n",
    "ece, mce = prob_metrics(df_preds)\n",
    "print(ece,mce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T11:24:13.375999Z",
     "start_time": "2022-03-09T11:24:13.342310Z"
    }
   },
   "outputs": [],
   "source": [
    "def brier_multi(targets, probs):\n",
    "    return np.mean(np.sum((probs - targets)**2, axis=1))\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "onehot = encoder.fit_transform(np.array(df_preds['actual']).reshape(-1, 1))\n",
    "brier_multi(onehot, df_preds[['0','1','2','3','4']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Latents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T14:14:03.968506Z",
     "start_time": "2022-03-02T14:14:03.958340Z"
    }
   },
   "outputs": [],
   "source": [
    "latents0 = torch.load('PATH to a random latents_0')\n",
    "latents = torch.load('PATH to a random latents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T14:14:05.597715Z",
     "start_time": "2022-03-02T14:14:04.318677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making Before and After latent-datasets \n",
    "df0 = pd.DataFrame(np.array(latents0['label_latents'][0]))\n",
    "df0['class'] = pd.Series(list(np.full((10,), 0)) + list(np.full((10,), 1)) + list(\n",
    "    np.full((10,), 2)) + list(np.full((10,), 3)) + list(np.full((10,), 4)))\n",
    "features0 = df0.iloc[:, :-1]\n",
    "df = pd.DataFrame(np.array(latents['label_latents'][0]))\n",
    "df['class'] = pd.Series(list(np.full((10,), 0)) + list(np.full((10,), 1)) + list(\n",
    "    np.full((10,), 2)) + list(np.full((10,), 3)) + list(np.full((10,), 4)))\n",
    "features = df.iloc[:, :-1]\n",
    "\n",
    "# UMAP projection to 2D space \n",
    "umap = UMAP(n_components=2, init='random', random_state=0)\n",
    "proj_2d0 = umap.fit_transform(features0)\n",
    "umap = UMAP(n_components=2, init='random', random_state=0)\n",
    "proj_2d = umap.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T14:14:06.122377Z",
     "start_time": "2022-03-02T14:14:06.115618Z"
    }
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.davies_bouldin_score(proj_2d0, df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T14:14:06.580566Z",
     "start_time": "2022-03-02T14:14:06.574312Z"
    }
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.davies_bouldin_score(proj_2d, df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "sns.relplot(x=proj_2d[:, 0], y=proj_2d[:, 1], hue=df['class'].astype(\n",
    "    int), palette=\"Dark2\", style=df['class'].astype(int), s=250, legend=False)\n",
    "a=sns.kdeplot(x=proj_2d[:, 0], y=proj_2d[:, 1],\n",
    "            hue=df['class'].astype(int), palette=\"Pastel2\", legend=False)\n",
    "sns.despine(right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.relplot(x=proj_2d0[:, 0], y=proj_2d0[:, 1], hue=df['class'].astype(\n",
    "    int), palette=\"Dark2\", style=df['class'].astype(int), s=250, legend=False)\n",
    "a=sns.kdeplot(x=proj_2d0[:, 0], y=proj_2d0[:, 1],\n",
    "            hue=df['class'].astype(int), palette=\"Pastel2\", legend=False)\n",
    "sns.despine(right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T13:52:28.902650Z",
     "start_time": "2022-03-02T13:52:28.790141Z"
    }
   },
   "outputs": [],
   "source": [
    "sfig = a.get_figure()\n",
    "sfig.savefig('label_latents0.jpeg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T14:14:13.747389Z",
     "start_time": "2022-03-02T14:14:12.729016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making Before and After latent-datasets \n",
    "df0 = pd.DataFrame(np.array(latents0['semantic_latents'][0]))\n",
    "df0['class'] = pd.Series(list(np.full((10,), 0)) + list(np.full((10,), 1)) + list(\n",
    "    np.full((10,), 2)) + list(np.full((10,), 3)) + list(np.full((10,), 4)))\n",
    "features0 = df0.iloc[:, :-1]\n",
    "df = pd.DataFrame(np.array(latents['semantic_latents'][0]))\n",
    "df['class'] = pd.Series(list(np.full((10,), 0)) + list(np.full((10,), 1)) + list(\n",
    "    np.full((10,), 2)) + list(np.full((10,), 3)) + list(np.full((10,), 4)))\n",
    "features = df.iloc[:, :-1]\n",
    "\n",
    "# UMAP projection to 2D space\n",
    "umap = UMAP(n_components=2, init='random', random_state=0)\n",
    "proj_2d0 = umap.fit_transform(features0)\n",
    "umap = UMAP(n_components=2, init='random', random_state=0)\n",
    "proj_2d = umap.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T14:14:41.630653Z",
     "start_time": "2022-03-02T14:14:41.624055Z"
    }
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.davies_bouldin_score(proj_2d0, df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T14:14:48.090858Z",
     "start_time": "2022-03-02T14:14:48.074650Z"
    }
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.davies_bouldin_score(proj_2d, df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.relplot(x=proj_2d[:, 0], y=proj_2d[:, 1], hue=df['class'].astype(\n",
    "    int), palette=\"Dark2\", style=df['class'].astype(int), s=250, legend=False)\n",
    "a=sns.kdeplot(x=proj_2d[:, 0], y=proj_2d[:, 1],\n",
    "            hue=df['class'].astype(int), palette=\"Pastel2\", legend=False)\n",
    "sns.despine(right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10, 6))\n",
    "sns.relplot(x=proj_2d0[:, 0], y=proj_2d0[:, 1], hue=df['class'].astype(\n",
    "    int), palette=\"Dark2\", style=df['class'].astype(int), s=250, legend=False)\n",
    "a= sns.kdeplot(x=proj_2d0[:, 0], y=proj_2d0[:, 1],\n",
    "            hue=df['class'].astype(int), palette=\"Pastel2\", legend=False)\n",
    "sns.despine(right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfig = a.get_figure()\n",
    "sfig.savefig('style_latents0.jpeg', dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "7e3af266dcb7df8b026f0780dbb396b062ee5ca2767a18f50e60e26ee6084121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.069px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
